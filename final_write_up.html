<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Parallelized Monte Carlo Tree Search for Go by 15618-final</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Parallelized Monte Carlo Tree Search for Go</h1>
      <h2 class="project-tagline">Qiankun Zhuang, Yepeng Yin, 15-618 Final Project</h2>
      <a href="http://15418-final.github.io/parallelizedMCTS_web" class="btn">Proposal</a>
      <a href="http://15418-final.github.io/parallelizedMCTS_web/checkpoint" class="btn">Checkpoint</a>
      <a href="http://15418-final.github.io/parallelizedMCTS_web/final_write_up" class="btn">Final Write Up</a>
      <a href="https://github.com/15418-final/ParallelizedMCTS" class="btn">View on GitHub</a>
    </section>

    <section class="main-content">
      <h2>
<a id="proposal" class="anchor" href="#proposal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Final Write Up</h2>

<h3>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>

<p>We implemented Monte Carlo Tree Search algorithm for Go, and parallelized it using OpenMP on CPU, and Cuda on GPU. 
Then we compared the performance of these three implementations. Our deliverables include figures describing the 
performance improvemnt in terms of number of simulated games, and win ratios between different implementations.</p>

<h3>
<a id="background" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>
<p>
  In this project we'll try to parallelize Monte Carlo Tree Search algoritm. The basic data structure we use here is tree. 
  The tree will grow from one single node, with the following 4 oeprations: Selection, Expansion, Simulation and Backpropagation. 
</p>
<p>
  Selection: If a node has been visited and searched before, we use some evaluation function to determine 
  which child node we should use to walk down the tree. This is a multi-arm bandit problem and here we use Upper Confidence bound
  applied to Trees (UCT) as the evaluation function, to balance exploration and exploition. 
</p>
<p>
  Expansion: If a node has not been searched before, we will try to expand the node by finding all possible next moves, 
  as the children of the node, which are also the leaf nodes of the tree. 
</p>
<p>
  Simulation: For the leaf nodes that are just expanded, we'll play lots of games on the node using random choices, and record
  the number of simulations and wins. The more simulations we do on a single node, the better performance we'll get. 
  Because all simulations are played independently, this is the main part we're going to parallelize.
</p>
<p>
  Backpropagation: For all the simulations we run on the leaf nodes, the number of wins and simulations will be propagated back to 
  its ancestors to update their records. Then we can find the best next move from the root node through its children's win/loss ratio.
  The picture folloing may help explain the 4 phases:
</p>
<p>
  <img src="http://15418-final.github.io/parallelizedMCTS_web/mcts.png" alt="MCTS" style="width:304px;height:228px;">
</p>
<p>
  Each node represents a state of the board. To generate a next move, we take the current board state as the root node. With the 
  4 operations described above, we grow the tree and selects the most promising children of root as next move. 
</p>
<p>
  As we know, tree traversal is very hard to parallelize, as there are many dependencies when you go down the tree. However, for 
  Monte Carlo Search Tree, most of the time is spent on Simulation phase on leaf nodes, and these simulation are totally independent 
  from each other. Therefore, there's a potential that we can make simulation phase parallel, so that in a fixed time we can do more 
  simulations for each state of board. Each thread can have a local copy of a board, and they can play randomly on their own board,
  and then report the result. 
</p>
<p>
  However, even though this is naturally parallizable, it's not good for SIMD. Because different threads play the game totally randomly, 
  they will have very different state of board, leading to lots of divergence. We found this problem when we try to run our program
  on a warp of threads on GPU.
</p>

<h3>
<p>
  <a id="approach" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Approach</h3>
</p>
<p>
  To implement, for CPU parallel version we use OpenMP, and for GPU parallel we use Cuda. Target machine is Latedays.
</p>
<p>
  At the very begining, we start our project based on Fuego, an open source Go project, to make use of the Go logic they implemented.
  We tried to understand the code base, interfaces it provides, and tries to parallelize. However, we gradually realize that 
  Fuego is not very friendly to our modification:
<p>
  1. Fuego provides a very complete and complicated Go logic, and the data structure they use to represent a board state is too large.
  If we parallelize and do tons of simulation at the same time, it will consume too much memory. We tried solving this problem by
  using a sequence of play to represent a state of board, instead of their own board data structure, and saves a lot of memory.
</p>
<p>
  2. We wanted to integrate cuda and GPU to Fuego, however, we have to rewrite most of Fuego's code to device code so that it can be 
  run in cuda device. This will be too much work. To avoid the trouble, we implemented a basic version of Go as cuda device code so 
  that we can do Go simulation on GPU.
</p>

<h4>
  Implement on CPU:
</h4>
<p>
  Leaf-parallel MCTS - On CPU, we used OpenMP to parallelize the Simulation phase of Monte Carlo Tree Search. As mentioned above, this phase starts
  on the leaf nodes of the tree, and plays randomly on board independently. In OpenMP, we generate a board in each threads private
  memory so that each thread can play on their own board to avoid conflicts. If sufficient time is given, the tree can become
  very large because of Go's large expoential search space. At first, we used Fuego's implementation of Board in each node, however,
  when tree becomes large, program consumes huge memory. Then we changed our tree implementation to that, each node doesn't store
  a board, instead, it stores the sequence how it reaches this current state. 
</p>
<h4>
  Implement on GPU:
</h4>
<p>
  Implementation on GPU is more complicated. For CPU version, we utilized Go logic implemented by Fuego. However, it's 
  hard to transplant Fuego's code to Cuda device code. After evaluating the workload, we decided to implement our own Go logic
  in device code. Our own Go logic is a simplified version of Go and is much more lightweight, which is good for parallelizing 
  simulation phase. Smaller data structure repsenting the board is also beneficial when we want to place board data in shared 
  memory to increase the speed for simulating. Some read-only parameters of mcts is stored in constant memory.
</p>
<p>
  Leaf-parallel MCTS - We move the simulation phase to GPU so that we can make use of more GPU threads. GPU threads is slower
  than CPU threads (~100 times slower) due to lower clock frequency. But we can still manage to achieve higher number of simulations
  by using more threads. After some testing, we found that for threads from same warp will be executed almost sequentially. The reason
  is a warp of threads is running in SIMD and uses same set of ALU units. These threads are making random plays, leading to 
  very different state of board. This will result in lots of divergence and degenerate to sequential execution. Therefore, we 
  can only increase thread number by increasing the number of blocks and use only one thread on each block. Note that we need to
  record the number of winning games and total simulations, we use two arraris of size Thread_num and each thread i only writes to
  array[i] to avoid the use of atomic operation. Then we use exclusive scan to sum up the numbers in the array. 
</p>
</p>
  Block-level MCTS - In leaf-parllel implementation, we parallelize the simulations on a single leaf node. In block-level MCTS,
  we do simulations on multiple leaf nodes in parallel. Each block is responsible for the simulations of a leaf node.
</p>
<p>
  Finally, when the GPU is doing simulation works, CPU is idle to wait for GPU. This is a good opportunity to utilize CPU. Based on this observation, we hybrid GPU and CPU to further improve our performance. 
  As shown in result, the hybrid method fully utilized CPU power when GPU is doing work.
</p>

<h3>
<a id="result" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Result</h3>


<h3>
<a id="reference" class="anchor" href="#reference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Reference</h3>

<p><em>[1] Rocki, Kamil, and Reiji Suda. "Parallel Monte Carlo Tree Search on GPU." SCAI. 2011.</em></p>
<p><em>[2] Jeff Bradberry, Introduction to Monte Carlo Tree Search, https://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/</em></p>
<p><em>[3] Guillaume M.J.-B Chaslot, "Parallel Monte Carlo Tree Search", Computers and Games: 6th International Conference</em></p> 
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/15418-final/parallelizedMCTS_web">Parallelized Monte Carlo Tree Search for Go</a> is maintained by <a href="https://github.com/15418-final">15418-final</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
